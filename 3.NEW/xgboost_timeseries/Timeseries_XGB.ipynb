{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nominated-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "atlantic-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "class XGBTimeSeries:\n",
    "    def __init__(self, dataset, datecol_name, valuecol_name, agg_level,\n",
    "    num_lags):\n",
    "        self.src_dataset = dataset\n",
    "        self.datecol_name = datecol_name\n",
    "        self.valuecol_name = valuecol_name\n",
    "        if agg_level not in ['H', 'D', 'M', 'Y']:\n",
    "            raise KeyError('Invalid aggregation level - must be in (H, D, M,Y)')\n",
    "        self.agg_level = agg_level\n",
    "        self.num_lags = num_lags\n",
    "        self.add_attributes = list(self.src_dataset.columns)\n",
    "        self.add_attributes.remove(self.valuecol_name)\n",
    "        self.add_attributes.remove(self.datecol_name)\n",
    "        self.dataset = self._preprocess_dataset()\n",
    "        self.X, self.y = self._feature_target_split()\n",
    "        self.model = None\n",
    "        self.model_add1 = None\n",
    "        \n",
    "        \n",
    "    def _preprocess_dataset(self):\n",
    "        df = self.src_dataset.copy()\n",
    "        df[self.datecol_name] = pd.to_datetime(df[self.datecol_name])\n",
    "        if self.agg_level == 'H':\n",
    "            df['Year'] = df[self.datecol_name].apply(lambda x: x.year)\n",
    "            df['Month'] = df[self.datecol_name].apply(lambda x: x.month)\n",
    "            df['DayOfWeek'] = df[self.datecol_name].apply(lambda x:\n",
    "            x.strftime('%A'))\n",
    "            df['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x in ['Saturday', 'Sunday'] else 0)\n",
    "            df['Hour'] = df[self.datecol_name].apply(lambda x: x.hour)\n",
    "            df['IsWorkTime'] = df['Hour'].apply(lambda x: 1 if x in [9, 10, 11, 12, 13, 14, 15, 16, 17] else 0)\n",
    "        elif self.agg_level == 'D':\n",
    "            df['Year'] = df[self.datecol_name].apply(lambda x: x.year)\n",
    "            df['Month'] = df[self.datecol_name].apply(lambda x: x.month)\n",
    "            df['DayOfWeek'] = df[self.datecol_name].apply(lambda x:\n",
    "            x.strftime('%A'))\n",
    "            df['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x in             ['Saturday', 'Sunday'] else 0)\n",
    "        elif self.agg_level == 'M':\n",
    "            df['Year'] = df[self.datecol_name].apply(lambda x: x.year)\n",
    "            df['Month'] = df[self.datecol_name].apply(lambda x: x.month)\n",
    "        else: # year\n",
    "            df['Year'] = df[self.datecol_name].apply(lambda x: x.year)\n",
    "        # create dummy variables from DayOfWeek - categorical\n",
    "        if 'DayOfWeek' in df.columns:\n",
    "            dummies = pd.get_dummies(df['DayOfWeek'], prefix='Is',\n",
    "            prefix_sep='')\n",
    "            dummies = dummies[['IsMonday', 'IsTuesday', 'IsWednesday',\n",
    "            'IsThursday', 'IsFriday', 'IsSaturday']]\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "            df.drop('DayOfWeek', axis=1, inplace=True)\n",
    "        # Create lagged variables\n",
    "        for i in range(1, self.num_lags + 1):\n",
    "            df[f'LAG_{i}'] = df[self.valuecol_name].shift(i)\n",
    "        for col in self.add_attributes:\n",
    "            for i in range(1, self.num_lags + 1):\n",
    "                df[f'LAG_{col}_{i}'] = df[col].shift(i)\n",
    "        df.dropna(inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def _feature_target_split(self):\n",
    "        # Drop date column because it can't be used\n",
    "        X = self.dataset.drop([self.datecol_name, self.valuecol_name]+self.add_attributes, axis=1)\n",
    "        y = self.dataset[self.valuecol_name]\n",
    "        return X, y\n",
    "    \n",
    "    def _agg_equals_expression(self, date, i):\n",
    "        if self.agg_level == 'H':\n",
    "            return date - relativedelta(hours=i)\n",
    "        elif self.agg_level == 'D':\n",
    "            return date - relativedelta(days=i)\n",
    "        elif self.agg_level == 'M':\n",
    "            return date - relativedelta(months=i)\n",
    "        else: # year\n",
    "            return date - relativedelta(years=i)\n",
    "        \n",
    "    def _get_column_list(self):\n",
    "        add_attributes = []\n",
    "        if self.agg_level == 'H':\n",
    "            return ['Year', 'Month', 'IsWeekend', 'Hour', 'IsWorkTime',\n",
    "            'IsMonday', 'IsTuesday', 'IsWednesday', 'IsThursday', 'IsFriday',\n",
    "            'IsSaturday'] + add_attributes\n",
    "        elif self.agg_level == 'D':\n",
    "            return ['Year', 'Month', 'IsWeekend', 'IsMonday', 'IsTuesday',\n",
    "            'IsWednesday', 'IsThursday', 'IsFriday', 'IsSaturday'] + add_attributes\n",
    "        elif self.agg_level == 'M':\n",
    "            return ['Year', 'Month'] + add_attributes\n",
    "        else:\n",
    "            return ['Year'] + add_attributes\n",
    "        \n",
    "    @staticmethod\n",
    "    def _one_hot_weekdays(day):\n",
    "        if day == 'Monday':\n",
    "            return [1, 0, 0, 0, 0, 0]\n",
    "        elif day == 'Tuesday':\n",
    "            return [0, 1, 0, 0, 0, 0]\n",
    "        elif day == 'Wednesday':\n",
    "            return [0, 0, 1, 0, 0, 0]\n",
    "        elif day == 'Thursday':\n",
    "            return [0, 0, 0, 1, 0, 0]\n",
    "        elif day == 'Friday':\n",
    "            return [0, 0, 0, 0, 1, 0]\n",
    "        elif day == 'Saturday':\n",
    "            return [0, 0, 0, 0, 0, 1]\n",
    "        else:\n",
    "            return [0, 0, 0, 0, 0, 0]\n",
    "        \n",
    "    def _get_attributes(self, date):\n",
    "        if self.agg_level == 'H':\n",
    "            year = date.year\n",
    "            month = date.month\n",
    "            dayofweek = date.strftime('%A')\n",
    "            isweekend = 1 if dayofweek in ['Saturday', 'Sunday'] else 0\n",
    "            dayofweek_onehot = self._one_hot_weekdays(dayofweek)\n",
    "            hour = date.hour\n",
    "            isworkhour = 1 if hour in [9, 10, 11, 12, 13, 14, 15, 16, 17] else 0\n",
    "            return [year, month, isweekend, hour, isworkhour,*dayofweek_onehot]\n",
    "        elif self.agg_level == 'D':\n",
    "            year = date.year\n",
    "            month = date.month\n",
    "            dayofweek = date.strftime('%A')\n",
    "            isweekend = 1 if dayofweek in ['Saturday', 'Sunday'] else 0\n",
    "            dayofweek_onehot = self._one_hot_weekdays(dayofweek)\n",
    "            return [year, month, isweekend, *dayofweek_onehot]\n",
    "        elif self.agg_level == 'M':\n",
    "            year = date.year\n",
    "            month = date.month\n",
    "            return [year, month]\n",
    "        else:\n",
    "            year = date.year\n",
    "            return [year]\n",
    "        \n",
    "    def _get_prediction_from_to_dates(self, data, n_periods):\n",
    "        if self.agg_level == 'H':\n",
    "            from_date = data.iloc[-1][self.datecol_name] +            relativedelta(hours=1)\n",
    "            thru_date = data.iloc[-1][self.datecol_name] +            relativedelta(hours=n_periods)\n",
    "            return from_date, thru_date\n",
    "        elif self.agg_level == 'D':\n",
    "            from_date = data.iloc[-1][self.datecol_name] +            relativedelta(days=1)\n",
    "            thru_date = data.iloc[-1][self.datecol_name] +            relativedelta(days=n_periods)\n",
    "            return from_date, thru_date\n",
    "        elif self.agg_level == 'M':\n",
    "            from_date = data.iloc[-1][self.datecol_name] + relativedelta(months=1)\n",
    "            thru_date = data.iloc[-1][self.datecol_name] + relativedelta(months=n_periods)\n",
    "            return from_date, thru_date\n",
    "        else: # year\n",
    "            from_date = data.iloc[-1][self.datecol_name] +            relativedelta(years=1)\n",
    "            thru_date = data.iloc[-1][self.datecol_name] +            relativedelta(years=n_periods)\n",
    "            return from_date, thru_date\n",
    "        \n",
    "        \n",
    "    def add_feature_sigle_predict(self, data, date):\n",
    "        model_add1 = XGBRegressor()\n",
    "        temp_col = self.add_attributes[0]\n",
    "        X_add = self.dataset[[\"Year\",'Month']+[i for i in self.dataset.columns if '_Temp' in i ]]\n",
    "        y_add = self.dataset[temp_col]\n",
    "        \n",
    "        model_add1.fit(X_add, y_add)\n",
    "        self.model_add1 = model_add1\n",
    "        #_single_predict_add ver\n",
    "        attributes = self._get_attributes(date)\n",
    "        column_names = self._get_column_list()\n",
    "        lags = []\n",
    "        lags_arr = []\n",
    "        for i in range(1, self.num_lags + 1):\n",
    "            for col in self.add_attributes:\n",
    "                lags.append(data[data[self.datecol_name] == self._agg_equals_expression(date, i)][col].values[0])\n",
    "                lags_arr.append(f'LAG_{col}_{i}')\n",
    "            \n",
    "        concatenated = [*attributes, *lags]\n",
    "        concatenated = pd.DataFrame(concatenated)\n",
    "        concatenated = concatenated.T\n",
    "        concatenated.columns = [*column_names, *lags_arr]\n",
    "        prediction = self.model_add1.predict(concatenated)\n",
    "        return prediction[0]\n",
    "        \n",
    "        \n",
    "    def _single_predict(self, data, date):\n",
    "        attributes = self._get_attributes(date)\n",
    "        column_names = self._get_column_list()\n",
    "        lags = []\n",
    "        lags_arr = []\n",
    "        for i in range(1, self.num_lags + 1):\n",
    "            lags.append(data[data[self.datecol_name] == self._agg_equals_expression(date, i)][self.valuecol_name].values[0])\n",
    "            lags_arr.append(f'LAG_{i}')\n",
    "        #####################################################    \n",
    "        for i in range(1, self.num_lags + 1):\n",
    "            for col in self.add_attributes:\n",
    "                lags.append(data[data[self.datecol_name] == self._agg_equals_expression(date, i)][col].values[0])\n",
    "                lags_arr.append(f'LAG_{col}_{i}')\n",
    "            \n",
    "        concatenated = [*attributes, *lags]\n",
    "        concatenated = pd.DataFrame(concatenated)\n",
    "        concatenated = concatenated.T\n",
    "        concatenated.columns = [*column_names, *lags_arr]\n",
    "        prediction = self.model.predict(concatenated)\n",
    "        return prediction[0]\n",
    "    \n",
    "    \n",
    "    def fit(self, X=None, y=None, hyperparameters=None):\n",
    "        if X is None: X = self.X\n",
    "        if y is None: y = self.y\n",
    "        if hyperparameters is None:\n",
    "            model = XGBRegressor()\n",
    "        else:\n",
    "            model = XGBRegressor(**hyperparameters)\n",
    "        model.fit(X, y)\n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, n_periods):\n",
    "        '''\n",
    "        Public method, used make predictions for a given number of periods.\n",
    "        Arguments:\n",
    "        n_periods -- int - number of periods to forecast in the future\n",
    "        Returns:\n",
    "        list of dicts - <Date: Prediction> pairs\n",
    "        '''\n",
    "        data = self.dataset.copy()\n",
    "        pred_from_date, pred_thru_date =self._get_prediction_from_to_dates(data, n_periods)\n",
    "        freq = 'MS' if self.agg_level == 'M' else self.agg_level\n",
    "        pred_date_range = pd.date_range(start=pred_from_date, end=pred_thru_date, freq=freq)\n",
    "        for date in pred_date_range:\n",
    "            spred = self._single_predict(data, date)\n",
    "            spred_add = self.add_feature_sigle_predict(data, date)\n",
    "            attributes = self._get_attributes(date)\n",
    "            \n",
    "            lags = list(data[-self.num_lags:][self.valuecol_name].values)\n",
    "            #adding add_atrribute cols\n",
    "            for col in self.add_attributes:\n",
    "                add_col_values =  data[-self.num_lags:][col].values\n",
    "            lags.extend(add_col_values)\n",
    "            \n",
    "            lags = lags[::-1]\n",
    "            \n",
    "            new_history = [date, spred, spred_add, *attributes, *lags]\n",
    "            new_history = pd.DataFrame(new_history)\n",
    "            new_history = new_history.T\n",
    "            new_history.columns = data.columns\n",
    "            data = pd.concat([data, new_history])\n",
    "            data = data.reset_index(drop=True)\n",
    "        predictions = []\n",
    "        for _, row in data[-n_periods:].iterrows():\n",
    "            predictions.append({\n",
    "            'Date': row[self.datecol_name],\n",
    "            'Prediction': row[self.valuecol_name]\n",
    "            })\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "periodic-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('./dataset.csv')\n",
    "df.columns = ['Date', 'Passengers']\n",
    "\n",
    "df['Temp'] = np.random.randint(0, 38, size = len(df))\n",
    "\n",
    "train_set, test_set = df[:-12], df[-12:]\n",
    "\n",
    "train_set['Date'] = train_set['Date'].apply(lambda x: (x + '-01'))\n",
    "train_set['Date'] = train_set['Date'].astype('datetime64')\n",
    "\n",
    "model = XGBTimeSeries(\n",
    "dataset=train_set,\n",
    "datecol_name='Date',\n",
    "valuecol_name='Passengers',\n",
    "agg_level='M',\n",
    "num_lags=12\n",
    ")\n",
    "\n",
    "model.fit(hyperparameters={'n_estimators': 2000})\n",
    "preds = model.predict(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "skilled-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Date': Timestamp('1960-01-01 00:00:00'), 'Prediction': 397.97696},\n",
       " {'Date': Timestamp('1960-02-01 00:00:00'), 'Prediction': 379.43735},\n",
       " {'Date': Timestamp('1960-03-01 00:00:00'), 'Prediction': 441.46313},\n",
       " {'Date': Timestamp('1960-04-01 00:00:00'), 'Prediction': 453.36874},\n",
       " {'Date': Timestamp('1960-05-01 00:00:00'), 'Prediction': 469.70456},\n",
       " {'Date': Timestamp('1960-06-01 00:00:00'), 'Prediction': 501.3307},\n",
       " {'Date': Timestamp('1960-07-01 00:00:00'), 'Prediction': 545.7566},\n",
       " {'Date': Timestamp('1960-08-01 00:00:00'), 'Prediction': 558.99603},\n",
       " {'Date': Timestamp('1960-09-01 00:00:00'), 'Prediction': 495.79346},\n",
       " {'Date': Timestamp('1960-10-01 00:00:00'), 'Prediction': 467.99545},\n",
       " {'Date': Timestamp('1960-11-01 00:00:00'), 'Prediction': 429.5537},\n",
       " {'Date': Timestamp('1960-12-01 00:00:00'), 'Prediction': 468.0182}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(preds)\n",
    "eval_df = pd.DataFrame({\n",
    "'Date': test_set['Date'],\n",
    "'Actual': test_set['Passengers'],\n",
    "'Predicted': preds['Prediction'].values\n",
    "})\n",
    "eval_df['AbsDiff'] = np.abs(eval_df['Actual'] - eval_df['Predicted'])\n",
    "eval_df['PctDiff'] = (eval_df['AbsDiff'] / eval_df['Actual']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = lambda act, pred: np.sqrt(mean_squared_error(act, pred))\n",
    "rmse(eval_df['Actual'], eval_df['Predicted'])\n",
    "# The result was 36.45489072358621 for me, indicating that our\n",
    "# model is expected to make an error of roughly 37 passengers,\n",
    "# positive or negative, on an average month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(eval_df['Actual'], label='Actual')\n",
    "plt.plot(eval_df['Predicted'], label='Predicted')\n",
    "plt.title('Airline Passengers - Actual vs Predicted', size=20)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-eating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-haiti",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
